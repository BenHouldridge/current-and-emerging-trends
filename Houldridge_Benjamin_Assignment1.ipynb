{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network to Identify Handwriten Characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "\n",
    "np.random.seed(1671) # for reproduciblity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Initial Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_EPOCH = 20\n",
    "BATCH_SIZE = 128\n",
    "VERBOSE = 1\n",
    "NB_CLASSES = 10 # number of outputs = number of digits\n",
    "OPTIMIZER = SGD() # optimixer\n",
    "N_HIDDEN = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Dataset for Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALIDATION_SPLIT=0.2 # how much TRAIN is reserved\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "#X_train is 60000 rows of 28x28 values --> reshaped in RESHAPED = 784\n",
    "RESHAPED = 784\n",
    "\n",
    "X_train = X_train.reshape(60000, RESHAPED)\n",
    "X_test = X_test.reshape(10000, RESHAPED)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print(X_train.shape[0], 'train samples') \n",
    "print(X_test.shape[0], 'test samples') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Class Vectors to Binary Class Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = np_utils.to_categorical(y_train, NB_CLASSES)\n",
    "Y_test = np_utils.to_categorical(y_test, NB_CLASSES) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1290      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 118,282\n",
      "Trainable params: 118,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(N_HIDDEN, input_shape=(RESHAPED,))) \n",
    "model.add(Activation('relu')) \n",
    "model.add(Dense(N_HIDDEN)) \n",
    "model.add(Activation('relu')) \n",
    "model.add(Dense(NB_CLASSES)) \n",
    "model.add(Activation('softmax')) # final stage is softmax\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy', optimizer=OPTIMIZER, metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 3s 66us/step - loss: 1.4829 - accuracy: 0.6231 - val_loss: 0.7584 - val_accuracy: 0.8286\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 3s 58us/step - loss: 0.6049 - accuracy: 0.8464 - val_loss: 0.4550 - val_accuracy: 0.8852\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 3s 59us/step - loss: 0.4398 - accuracy: 0.8801 - val_loss: 0.3710 - val_accuracy: 0.9019\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 3s 60us/step - loss: 0.3767 - accuracy: 0.8952 - val_loss: 0.3322 - val_accuracy: 0.9082\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 3s 62us/step - loss: 0.3415 - accuracy: 0.9025 - val_loss: 0.3055 - val_accuracy: 0.9147\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 3s 58us/step - loss: 0.3175 - accuracy: 0.9086 - val_loss: 0.2880 - val_accuracy: 0.9182\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 3s 58us/step - loss: 0.2989 - accuracy: 0.9137 - val_loss: 0.2727 - val_accuracy: 0.9224\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 3s 56us/step - loss: 0.2839 - accuracy: 0.9180 - val_loss: 0.2608 - val_accuracy: 0.9266\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 3s 59us/step - loss: 0.2714 - accuracy: 0.9217 - val_loss: 0.2505 - val_accuracy: 0.9298\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 3s 59us/step - loss: 0.2602 - accuracy: 0.9252 - val_loss: 0.2430 - val_accuracy: 0.9308\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 3s 59us/step - loss: 0.2501 - accuracy: 0.9285 - val_loss: 0.2341 - val_accuracy: 0.9335\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 3s 71us/step - loss: 0.2409 - accuracy: 0.9301 - val_loss: 0.2271 - val_accuracy: 0.9352\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 3s 62us/step - loss: 0.2325 - accuracy: 0.9334 - val_loss: 0.2227 - val_accuracy: 0.9367\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 3s 60us/step - loss: 0.2253 - accuracy: 0.9353 - val_loss: 0.2147 - val_accuracy: 0.9396\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 3s 61us/step - loss: 0.2181 - accuracy: 0.9375 - val_loss: 0.2082 - val_accuracy: 0.9411\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 3s 60us/step - loss: 0.2116 - accuracy: 0.9394 - val_loss: 0.2030 - val_accuracy: 0.9431\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 3s 62us/step - loss: 0.2055 - accuracy: 0.9414 - val_loss: 0.1981 - val_accuracy: 0.9445\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 3s 62us/step - loss: 0.1996 - accuracy: 0.9430 - val_loss: 0.1932 - val_accuracy: 0.9458\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 3s 63us/step - loss: 0.1941 - accuracy: 0.9432 - val_loss: 0.1894 - val_accuracy: 0.9467\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 3s 62us/step - loss: 0.1890 - accuracy: 0.9456 - val_loss: 0.1849 - val_accuracy: 0.9498\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, \n",
    "                    Y_train, \n",
    "                    batch_size=BATCH_SIZE, \n",
    "                    epochs=NB_EPOCH, \n",
    "                    verbose=VERBOSE, \n",
    "                    validation_split=VALIDATION_SPLIT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 44us/step\n",
      "Test score: 0.18599770209044217\n",
      "Test accuracy: 0.9463000297546387\n"
     ]
    }
   ],
   "source": [
    "example_score = model.evaluate(X_test, Y_test, verbose=VERBOSE)\n",
    "print(\"Test score:\", example_score[0]) \n",
    "print('Test accuracy:', example_score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment with Hidden Neuron Density\n",
    "\n",
    "### 16 Hidden Neurons per Layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_HIDDEN = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rebuild Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 16)                12560     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                170       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 13,002\n",
      "Trainable params: 13,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(N_HIDDEN, input_shape=(RESHAPED,))) \n",
    "model.add(Activation('relu')) \n",
    "model.add(Dense(N_HIDDEN)) \n",
    "model.add(Activation('relu')) \n",
    "model.add(Dense(NB_CLASSES)) \n",
    "model.add(Activation('softmax')) # final stage is softmax\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy', optimizer=OPTIMIZER, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrain Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 2s 37us/step - loss: 1.9488 - accuracy: 0.4018 - val_loss: 1.4643 - val_accuracy: 0.6260\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 2s 32us/step - loss: 1.1018 - accuracy: 0.7194 - val_loss: 0.7844 - val_accuracy: 0.7986\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 1s 30us/step - loss: 0.6842 - accuracy: 0.8158 - val_loss: 0.5600 - val_accuracy: 0.8513\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 1s 30us/step - loss: 0.5292 - accuracy: 0.8540 - val_loss: 0.4576 - val_accuracy: 0.8737\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 1s 27us/step - loss: 0.4547 - accuracy: 0.8717 - val_loss: 0.4080 - val_accuracy: 0.8857\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 2s 32us/step - loss: 0.4133 - accuracy: 0.8837 - val_loss: 0.3773 - val_accuracy: 0.8936\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 1s 25us/step - loss: 0.3863 - accuracy: 0.8908 - val_loss: 0.3579 - val_accuracy: 0.8978\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 0.3669 - accuracy: 0.8944 - val_loss: 0.3410 - val_accuracy: 0.9030\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 1s 29us/step - loss: 0.3513 - accuracy: 0.8995 - val_loss: 0.3295 - val_accuracy: 0.9066\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 1s 30us/step - loss: 0.3390 - accuracy: 0.9034 - val_loss: 0.3187 - val_accuracy: 0.9097\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 1s 31us/step - loss: 0.3280 - accuracy: 0.9060 - val_loss: 0.3118 - val_accuracy: 0.9119\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 1s 30us/step - loss: 0.3186 - accuracy: 0.9091 - val_loss: 0.3025 - val_accuracy: 0.9155\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 1s 30us/step - loss: 0.3103 - accuracy: 0.9114 - val_loss: 0.2960 - val_accuracy: 0.9157\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 1s 28us/step - loss: 0.3027 - accuracy: 0.9134 - val_loss: 0.2887 - val_accuracy: 0.9178\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 1s 30us/step - loss: 0.2961 - accuracy: 0.9153 - val_loss: 0.2838 - val_accuracy: 0.9198\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 1s 31us/step - loss: 0.2897 - accuracy: 0.9174 - val_loss: 0.2782 - val_accuracy: 0.9211\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 1s 31us/step - loss: 0.2842 - accuracy: 0.9185 - val_loss: 0.2751 - val_accuracy: 0.9218\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 1s 30us/step - loss: 0.2788 - accuracy: 0.9205 - val_loss: 0.2688 - val_accuracy: 0.9243\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 1s 30us/step - loss: 0.2739 - accuracy: 0.9211 - val_loss: 0.2656 - val_accuracy: 0.9251\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 1s 30us/step - loss: 0.2695 - accuracy: 0.9230 - val_loss: 0.2627 - val_accuracy: 0.9252\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, \n",
    "                    Y_train, \n",
    "                    batch_size=BATCH_SIZE, \n",
    "                    epochs=NB_EPOCH, \n",
    "                    verbose=VERBOSE, \n",
    "                    validation_split=VALIDATION_SPLIT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 20us/step\n"
     ]
    }
   ],
   "source": [
    "score_16_hidden = model.evaluate(X_test, Y_test, verbose=VERBOSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1024 Hidden Neurons per Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_HIDDEN = 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rebuild Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 1024)              803840    \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                10250     \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,863,690\n",
      "Trainable params: 1,863,690\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(N_HIDDEN, input_shape=(RESHAPED,))) \n",
    "model.add(Activation('relu')) \n",
    "model.add(Dense(N_HIDDEN)) \n",
    "model.add(Activation('relu')) \n",
    "model.add(Dense(NB_CLASSES)) \n",
    "model.add(Activation('softmax')) # final stage is softmax\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy', optimizer=OPTIMIZER, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrain Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 19s 389us/step - loss: 1.1816 - accuracy: 0.7564 - val_loss: 0.5605 - val_accuracy: 0.8783\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 18s 377us/step - loss: 0.4825 - accuracy: 0.8815 - val_loss: 0.3837 - val_accuracy: 0.9007\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 19s 390us/step - loss: 0.3783 - accuracy: 0.8986 - val_loss: 0.3288 - val_accuracy: 0.9112\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 22s 462us/step - loss: 0.3340 - accuracy: 0.9074 - val_loss: 0.2992 - val_accuracy: 0.9168\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 19s 396us/step - loss: 0.3061 - accuracy: 0.9145 - val_loss: 0.2785 - val_accuracy: 0.9204\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 19s 400us/step - loss: 0.2861 - accuracy: 0.9198 - val_loss: 0.2629 - val_accuracy: 0.9250\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 19s 398us/step - loss: 0.2698 - accuracy: 0.9245 - val_loss: 0.2514 - val_accuracy: 0.9283\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 20s 413us/step - loss: 0.2564 - accuracy: 0.9279 - val_loss: 0.2395 - val_accuracy: 0.9314\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 20s 409us/step - loss: 0.2446 - accuracy: 0.9312 - val_loss: 0.2314 - val_accuracy: 0.9341\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 20s 408us/step - loss: 0.2342 - accuracy: 0.9341 - val_loss: 0.2222 - val_accuracy: 0.9368\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 20s 419us/step - loss: 0.2244 - accuracy: 0.9371 - val_loss: 0.2149 - val_accuracy: 0.9387\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 20s 408us/step - loss: 0.2155 - accuracy: 0.9395 - val_loss: 0.2088 - val_accuracy: 0.9407\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 20s 412us/step - loss: 0.2074 - accuracy: 0.9415 - val_loss: 0.2017 - val_accuracy: 0.9453\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 20s 418us/step - loss: 0.1998 - accuracy: 0.9434 - val_loss: 0.1953 - val_accuracy: 0.9451\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 21s 429us/step - loss: 0.1925 - accuracy: 0.9454 - val_loss: 0.1892 - val_accuracy: 0.9482\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 21s 432us/step - loss: 0.1860 - accuracy: 0.9479 - val_loss: 0.1830 - val_accuracy: 0.9497\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 22s 454us/step - loss: 0.1796 - accuracy: 0.9499 - val_loss: 0.1791 - val_accuracy: 0.9496\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 19s 402us/step - loss: 0.1739 - accuracy: 0.9514 - val_loss: 0.1755 - val_accuracy: 0.9510\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 19s 397us/step - loss: 0.1681 - accuracy: 0.9530 - val_loss: 0.1703 - val_accuracy: 0.9534\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 20s 409us/step - loss: 0.1631 - accuracy: 0.9542 - val_loss: 0.1655 - val_accuracy: 0.9544\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, \n",
    "                    Y_train, \n",
    "                    batch_size=BATCH_SIZE, \n",
    "                    epochs=NB_EPOCH, \n",
    "                    verbose=VERBOSE, \n",
    "                    validation_split=VALIDATION_SPLIT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 5s 470us/step\n"
     ]
    }
   ],
   "source": [
    "score_1024_hidden = model.evaluate(X_test, Y_test, verbose=VERBOSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original 128 neurons per hidden layer\n",
      "Test score: 0.18599770209044217\n",
      "Test accuracy: 0.9463000297546387\n",
      "\n",
      "16 neurons per hidden layer\n",
      "Test score: 0.25991266669929025\n",
      "Test accuracy: 0.9240999817848206\n",
      "\n",
      "1024 neurons per hidden layer\n",
      "Test score: 0.164773375582695\n",
      "Test accuracy: 0.9516000151634216\n"
     ]
    }
   ],
   "source": [
    "print(\"Original 128 neurons per hidden layer\")\n",
    "print(\"Test score:\", example_score[0]) \n",
    "print('Test accuracy:', example_score[1])\n",
    "print()\n",
    "print(\"16 neurons per hidden layer\")\n",
    "print(\"Test score:\", score_16_hidden[0]) \n",
    "print('Test accuracy:', score_16_hidden[1])\n",
    "print()\n",
    "print(\"1024 neurons per hidden layer\")\n",
    "print(\"Test score:\", score_1024_hidden[0]) \n",
    "print('Test accuracy:', score_1024_hidden[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "    Above I have changed the number of neurons in the 2 hidden layers in this neural network. I experimented with 16, 128, and 1025 neurons per layer. This does not affect the training or testing data but does have an effect on the outcome of the model. With each increase in the number of neurons we saw an increase in the validation accuracy rate and a decrease in the loss. This shows that the model is better at predicting the handwritten digits and isn’t overtraining. The cost of this though is computation. The 16 neurons took 1 second to train each epoch, the 128 neurons took 3 seconds, and the 1025 neurons took 20 seconds. This accelerating cost in computation is also paired with a diminishing return in accuracy. The validation accuracy only increased from 92% with 16 neurons, to 94.6% with 128, and 95.2% for 1025 neurons. This diminishing returns suggests that for a specific set of constraints there is an optimal number of neurons that will generate the best accuracy without sacrificing unnecessary computational resources, and time."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
